{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "\n",
    "# Use a service account.\n",
    "cred = credentials.Certificate('firebase-svc-account-key.json')\n",
    "\n",
    "app = firebase_admin.initialize_app(cred)\n",
    "\n",
    "db = firestore.client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문서 필드\n",
    "```bash\n",
    "cost_per_hour: 0.87389\n",
    "cpu: 8\n",
    "gpu: null\n",
    "name: \"c3.2xlarge\"\n",
    "ram: 15\n",
    "region: \"ap-northeast-2\"\n",
    "vendor: \"AWS\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_result = {'gcp': {'instance': {'cloud_provider': 'GCP',\n",
    "   'name': 'f1-micro',\n",
    "   'cpu': 1,\n",
    "   'ram': 0.6,\n",
    "   'storage': 30,\n",
    "   'gpu': 'None'},\n",
    "  'power_consumption': {'monthly': '13.14 kWh', 'hourly': '0.018 kWh'},\n",
    "  'carbon_footprint': {'monthly': '5.69 kg CO2', 'hourly': '0.008 kg CO2'},\n",
    "  'description': \"This application is a simple TODO backend application with minimal resource requirements. Thus, a small instance like the f1-micro should be sufficient to handle normal traffic. It comes with 1 vCPU and 0.6 GB of RAM. We'll assume 30GB storage is sufficient. The estimated power consumption and carbon footprint are based on Google Cloud's sustainability calculator, assuming the instance runs 24/7 in the us-central1 region.\"},\n",
    " 'aws': {'instance': {'cloud_provider': 'AWS',\n",
    "   'name': 't4g.nano',\n",
    "   'cpu': 2,\n",
    "   'ram': 0.5,\n",
    "   'storage': 30,\n",
    "   'gpu': 'None'},\n",
    "  'power_consumption': {'monthly': '8.76 kWh', 'hourly': '0.012 kWh'},\n",
    "  'carbon_footprint': {'monthly': '3.77 kg CO2', 'hourly': '0.005 kg CO2'},\n",
    "  'description': \"For AWS, we'll opt for the t4g.nano instance, offering 2 vCPUs and 0.5 GB of RAM, which is suitable for this lightweight application. We'll assume 30GB storage is sufficient. Power consumption and carbon footprint estimations are derived from AWS's carbon footprint tools, considering 24/7 operation in the us-east-1 region.\"},\n",
    " 'azure': {'instance': {'cloud_provider': 'Azure',\n",
    "   'name': 'B1s',\n",
    "   'cpu': 1,\n",
    "   'ram': 1,\n",
    "   'storage': 30,\n",
    "   'gpu': 'None'},\n",
    "  'power_consumption': {'monthly': '10.44 kWh', 'hourly': '0.014 kWh'},\n",
    "  'carbon_footprint': {'monthly': '4.5 kg CO2', 'hourly': '0.006 kg CO2'},\n",
    "  'description': \"On Azure, the B1s instance appears suitable for this application. It comes with 1 vCPU and 1 GB of RAM. We'll assume 30GB storage is sufficient.  The power consumption and carbon footprint figures are based on Azure's sustainability calculator, assuming continuous operation in the East US region.\"},\n",
    " 'conclusion': {'instance': {'cloud_provider': 'AWS',\n",
    "   'name': 't4g.nano',\n",
    "   'cpu': 2,\n",
    "   'ram': 0.5,\n",
    "   'storage': 30,\n",
    "   'gpu': 'None'},\n",
    "  'power_consumption': {'monthly': '8.76 kWh', 'hourly': '0.012 kWh'},\n",
    "  'carbon_footprint': {'monthly': '3.77 kg CO2', 'hourly': '0.005 kg CO2'},\n",
    "  'description': \"Based on the analysis, while all three cloud providers offer suitable instances for this TODO application, AWS's t4g.nano instance emerges as the most efficient option. It offers a balance of performance and low resource consumption, resulting in the lowest estimated power consumption and carbon footprint.\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cpu': 2,\n",
       " 'ram': 0.5,\n",
       " 'cost_per_hour': 0.0042,\n",
       " 'region': 'us-east-1',\n",
       " 'gpu': None,\n",
       " 'vendor': 'AWS',\n",
       " 'name': 't4g.nano'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "from google.cloud.firestore_v1.base_query import FieldFilter, Or, And\n",
    "\n",
    "vendor = gemini_result[\"aws\"][\"instance\"][\"cloud_provider\"]\n",
    "name = gemini_result[\"aws\"][\"instance\"][\"name\"]\n",
    "cpu = gemini_result[\"aws\"][\"instance\"][\"cpu\"]\n",
    "ram = gemini_result[\"aws\"][\"instance\"][\"ram\"]\n",
    "ref = db.collection(\"cloud_cost\")\n",
    "vendor_filter = FieldFilter(\"vendor\", \"==\", vendor)\n",
    "name_filter = FieldFilter(\"name\", \"==\", name)\n",
    "cpu_filter = FieldFilter(\"cpu\", \"==\", cpu)\n",
    "ram_filter = FieldFilter(\"ram\", \"==\", ram)\n",
    "resource_filter = And(filters=[cpu_filter, ram_filter])\n",
    "instance_filter = Or(filters=[name_filter, resource_filter])\n",
    "final_filter = And(filters=[vendor_filter, instance_filter])\n",
    "docs = ref.where(filter=final_filter).stream()\n",
    "\n",
    "lowest_instance = {\"cost_per_hour\": float(\"inf\")}\n",
    "for doc in docs:\n",
    "    if lowest_instance[\"cost_per_hour\"] > doc.to_dict()[\"cost_per_hour\"]:\n",
    "        lowest_instance = doc.to_dict()\n",
    "lowest_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
