{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repo Chain\n",
    "- repo를 보고 cloud provider instance 정보 추출\n",
    "- Language ratio 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Git Analyzer\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Optional\n",
    "from langchain_core.output_parsers import JsonOutputParser, PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Instance(BaseModel):\n",
    "    cloud_provider: str = Field(description=\"Name of cloud provider (GCP or AWS or Azure)\")\n",
    "    name: str = Field(description=\"Name of instance type\")\n",
    "    cpu: int = Field(description=\"The number of instance cpu cores\")\n",
    "    ram: float = Field(description=\"The capacity of instance ram (GiB)\")\n",
    "    storage: int = Field(description=\"The capacity of instance storage (GiB)\")\n",
    "    gpu: Optional[str] = Field(default=None, description=\"Name of gpu model and memory (GiB) of instance\")\n",
    "    region: str = Field(description=\"Region of instance\")\n",
    "    cost_per_hour: float = Field(description=\"Cost per Hour of instance\")\n",
    "    description: str = Field(description=\"The detailed process that led to the selection of the minimum specification instance.\")\n",
    "    \n",
    "class RepoResult(BaseModel):\n",
    "    gcp: Instance = Field(description=\"Instance information of GCP\")\n",
    "    aws: Instance = Field(description=\"Instance information of AWS\")\n",
    "    azure: Instance = Field(description=\"Instance information of Azure\")\n",
    "    language_ratio: Dict[str, int] = Field(description=\"The key value is the programming language used and the value is the number of bytes the programming language is used in the entire repository.\")\n",
    "\n",
    "# output_parser = JsonOutputParser(pydantic_object=RepoResult)\n",
    "output_parser = PydanticOutputParser(pydantic_object=RepoResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722680190.988095   21583 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1722680190.989008   21583 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"models/gemini-1.5-pro-latest\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722680191.936129   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680191.936322   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680191.979675   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680191.979920   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.012846   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.013070   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.045877   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.046120   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.077191   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.077458   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.107748   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.107951   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.138332   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.138552   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.169820   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.170025   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.203046   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.203277   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.234059   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.234270   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.264691   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.264905   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.295615   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.295814   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.326533   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.326729   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.358241   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.358484   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.388686   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.388882   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.418665   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.418870   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.448357   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.448557   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.477823   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.478004   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.508283   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.508474   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.538185   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.538403   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.567622   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.567801   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.598213   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.598405   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.628421   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.628628   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.658079   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.658294   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.687419   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.687610   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.717337   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.717524   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.746198   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.746403   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.775892   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.776080   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.806074   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.806269   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.835950   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.836124   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.865263   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.865470   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.894959   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.895155   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.924592   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.924784   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.954057   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.954272   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680192.983777   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680192.984011   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.014303   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.014539   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.044947   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.045129   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.073949   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.074185   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.103960   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.104151   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.133423   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.133613   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.163091   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.163348   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.192696   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.192878   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.222896   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.223104   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.253162   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.253355   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.283491   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.283717   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.312760   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.312972   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.342179   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.342381   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.371814   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.371998   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.401576   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.401783   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.432043   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.432286   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.462490   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.462680   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.491928   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.492140   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.521493   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.521702   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.551103   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.551308   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.581008   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.581218   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.611111   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.611286   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.641836   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.642060   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.671895   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.672103   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.701544   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.701757   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.731324   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.731508   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.761290   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.761500   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.790960   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.791169   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.820553   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.820748   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.851289   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.851533   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.881289   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.881476   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1722680193.911192   21583 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680193.911391   21583 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import GitLoader\n",
    "\n",
    "repo_path = \"./repo/todo\"\n",
    "loader = GitLoader(\n",
    "    clone_url=\"https://github.com/rjwharry/todo.git\",\n",
    "    repo_path=repo_path,\n",
    "    branch=\"main\",\n",
    ")\n",
    "data = loader.load()\n",
    "backend = list(filter(lambda d: d.metadata[\"source\"].startswith(\"backend/\"), data))\n",
    "len(backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "# Output\n",
    "# Ensure the output is structured in a clear and detailed manner, adhering to the JSON format specified by the following guide: {format_instruction}\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "As an expert in analyzing software repositories and estimating resource consumption and environmental impact, your task is to provide a comprehensive analysis of a GitHub repository.\n",
    "\n",
    "Instructions\n",
    "Analyze the structure of the files in the provided GitHub repository by examining the metadata in the documentation.\n",
    "Identify the entry point of the repository.\n",
    "Determine the minimum resources required to run the repository on GCP, AWS, and Azure platforms.\n",
    "Estimate the power consumption, and carbon footprint on each platform.\n",
    "{format_instruction}\n",
    "Context\n",
    "The goal is to gain a detailed understanding of the repository’s requirements and its environmental impact. Your analysis should be thorough, taking into account all relevant aspects of the repository and the different cloud platforms.\n",
    "\n",
    "\n",
    "GitHub Repository\n",
    "{GITHUB}\n",
    "\n",
    "Additional Guidelines\n",
    "Be specific and detailed in your analysis.\n",
    "Provide calculations and assumptions used in estimating resources and environmental impact.\n",
    "Compare and contrast the findings across the three cloud platforms (GCP, AWS, Azure).\n",
    "Use technical terminology appropriately to convey precision and expertise.\n",
    "\"\"\",\n",
    "    input_variables=[\"GITHUB\"],\n",
    "    partial_variables={\"format_instruction\": output_parser.get_format_instructions()}\n",
    "    )\n",
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722680214.542598   53315 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722680214.542884   53315 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    }
   ],
   "source": [
    "gemini_result = chain.invoke({\"GITHUB\": backend})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcp=Instance(cloud_provider='GCP', name='e2-medium', cpu=2, ram=4.0, storage=10, gpu='None', region='us-central1', cost_per_hour=0.0516, description=\"This application requires a minimum of 2 vCPUs and 2GB of RAM to run. A simple Java application with Spring Boot and MySQL usually doesn't demand high CPU or memory resources. Therefore, an e2-medium instance, which provides a balance of performance and cost, is chosen. 10GB of storage is sufficient for this application and its data. The application does not require a GPU. The us-central1 region offers a good balance of cost and latency for many users.\") aws=Instance(cloud_provider='AWS', name='t3.medium', cpu=2, ram=4.0, storage=10, gpu='None', region='us-east-1', cost_per_hour=0.0468, description=\"This application requires a minimum of 2 vCPUs and 2GB of RAM to run. A simple Java application with Spring Boot and MySQL usually doesn't demand high CPU or memory resources. Therefore, a t3.medium instance, which provides a balance of performance and cost, is chosen. 10GB of storage is sufficient for this application and its data. The application does not require a GPU. The us-east-1 region offers a good balance of cost and latency for many users.\") azure=Instance(cloud_provider='Azure', name='Standard_B2s', cpu=2, ram=4.0, storage=10, gpu='None', region='eastus', cost_per_hour=0.0456, description=\"This application requires a minimum of 2 vCPUs and 2GB of RAM to run. A simple Java application with Spring Boot and MySQL usually doesn't demand high CPU or memory resources. Therefore, a Standard_B2s instance, which provides a balance of performance and cost, is chosen. 10GB of storage is sufficient for this application and its data. The application does not require a GPU. The eastus region offers a good balance of cost and latency for many users.\") language_ratio={'Kotlin': 1754, 'Properties': 1056, 'YAML': 810, 'Shell': 3607, 'Batch': 2830, 'JSON': 2742}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Instance(cloud_provider='AWS', name='t3.medium', cpu=2, ram=4.0, storage=10, gpu='None', region='us-east-1', cost_per_hour=0.0468, description=\"This application requires a minimum of 2 vCPUs and 2GB of RAM to run. A simple Java application with Spring Boot and MySQL usually doesn't demand high CPU or memory resources. Therefore, a t3.medium instance, which provides a balance of performance and cost, is chosen. 10GB of storage is sufficient for this application and its data. The application does not require a GPU. The us-east-1 region offers a good balance of cost and latency for many users.\")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gemini_result)\n",
    "repo_result = gemini_result\n",
    "repo_result.aws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Best Instance\n",
    "- gemini에서 추론한 instance spec을 기반으로 최신 데이터와 대조하여 가장 싼 가격의 instance 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import inf\n",
    "from typing import Dict\n",
    "from google.cloud.firestore_v1.base_query import FieldFilter, Or, And\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "\n",
    "def get_latest_price(instance: Instance) -> Instance:\n",
    "    if not firebase_admin._apps:\n",
    "        cred = credentials.Certificate('firebase-svc-account-key.json')\n",
    "        app = firebase_admin.initialize_app(cred)\n",
    "    db = firestore.client()\n",
    "    ref = db.collection(\"cloud_cost\")\n",
    "    vendor_filter = FieldFilter(\"vendor\", \"==\", instance.cloud_provider)\n",
    "    name_filter = FieldFilter(\"name\", \"==\", instance.name)\n",
    "    cpu_filter = FieldFilter(\"cpu\", \"==\", instance.cpu)\n",
    "    ram_filter = FieldFilter(\"ram\", \"==\", instance.ram)\n",
    "    resource_filter = And(filters=[cpu_filter, ram_filter])\n",
    "    instance_filter = Or(filters=[name_filter, resource_filter])\n",
    "    final_filter = And(filters=[vendor_filter, instance_filter])\n",
    "    docs = ref.where(filter=final_filter).stream()\n",
    "\n",
    "    lowest_instance = {\"cost_per_hour\": float(inf)}\n",
    "    for doc in docs:\n",
    "        if lowest_instance[\"cost_per_hour\"] > doc.to_dict()[\"cost_per_hour\"]:\n",
    "            lowest_instance = doc.to_dict()\n",
    "    instance = Instance(\n",
    "        cloud_provider=instance.cloud_provider,\n",
    "        name=lowest_instance[\"name\"], \n",
    "        cpu=lowest_instance[\"cpu\"], \n",
    "        ram=lowest_instance[\"ram\"], \n",
    "        storage=instance.storage,\n",
    "        gpu=lowest_instance[\"gpu\"],\n",
    "        region=lowest_instance[\"region\"],\n",
    "        cost_per_hour=lowest_instance[\"cost_per_hour\"],\n",
    "        description=instance.description,\n",
    "    )\n",
    "    return instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_aws_instance = get_latest_price(repo_result.aws)\n",
    "best_gcp_instance = get_latest_price(repo_result.gcp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_result.aws = best_aws_instance\n",
    "repo_result.gcp = best_gcp_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RepoResult(gcp=Instance(cloud_provider='GCP', name='e2-medium', cpu=1, ram=4.0, storage=10, gpu=None, region='us-central1', cost_per_hour=0.0169861111111111, description=\"This application requires a minimum of 2 vCPUs and 2GB of RAM to run. A simple Java application with Spring Boot and MySQL usually doesn't demand high CPU or memory resources. Therefore, an e2-medium instance, which provides a balance of performance and cost, is chosen. 10GB of storage is sufficient for this application and its data. The application does not require a GPU. The us-central1 region offers a good balance of cost and latency for many users.\"), aws=Instance(cloud_provider='AWS', name='t3.medium', cpu=2, ram=4.0, storage=10, gpu=None, region='us-east-1', cost_per_hour=0.0441, description=\"This application requires a minimum of 2 vCPUs and 2GB of RAM to run. A simple Java application with Spring Boot and MySQL usually doesn't demand high CPU or memory resources. Therefore, a t3.medium instance, which provides a balance of performance and cost, is chosen. 10GB of storage is sufficient for this application and its data. The application does not require a GPU. The us-east-1 region offers a good balance of cost and latency for many users.\"), azure=Instance(cloud_provider='Azure', name='Standard_B2s', cpu=2, ram=4.0, storage=10, gpu='None', region='eastus', cost_per_hour=0.0456, description=\"This application requires a minimum of 2 vCPUs and 2GB of RAM to run. A simple Java application with Spring Boot and MySQL usually doesn't demand high CPU or memory resources. Therefore, a Standard_B2s instance, which provides a balance of performance and cost, is chosen. 10GB of storage is sufficient for this application and its data. The application does not require a GPU. The eastus region offers a good balance of cost and latency for many users.\"), language_ratio={'Kotlin': 1754, 'Properties': 1056, 'YAML': 810, 'Shell': 3607, 'Batch': 2830, 'JSON': 2742})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate estimated power consumption and carbon footprint\n",
    "- RepoResult를 기반으로 각 instance의 power consumption과 carbon footprint 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from langchain_core.output_parsers import JsonOutputParser, PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Estimate(BaseModel):\n",
    "    power_consumption: str = Field(description=\"Estimated hourly power consumption while running an instance of the instance_type(kWh)\")\n",
    "    carbon_footprint: str = Field(description=\"Estimated hourly carbon footprint while running an instance of the instance_type(kg CO2)\")\n",
    "    description: str = Field(description=\"Detailed calculation process for estimating power consumption and carbon emissions.\")\n",
    "    \n",
    "class CalculateResult(BaseModel):\n",
    "    gcp: Estimate = Field(description=\"Estimate result of GCP\")\n",
    "    aws: Estimate = Field(description=\"Estimate result of AWS\")\n",
    "    azure: Estimate = Field(description=\"Estimate result of Azure\")\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=CalculateResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "# Output\n",
    "# Ensure the output is structured in a clear and detailed manner, adhering to the JSON format specified by the following guide: {format_instruction}\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"As an expert in cloud computing and sustainability, provide a detailed estimation of the hourly power consumption and carbon footprint for the specified instance specs from the leading cloud providers: AWS, GCP, and Azure.\n",
    "\n",
    "Instructions:\n",
    "Analyze the instance specifications provided for each cloud provider.\n",
    "Calculate the hourly power consumption based on the given specs.\n",
    "Estimate the carbon footprint associated with the hourly power consumption.\n",
    "Use the most recent data and metrics available for accurate estimations.\n",
    "Present the results clearly and concisely.\n",
    "Instance Specifications:\n",
    "AWS: {aws}\n",
    "\n",
    "GCP: {gcp}\n",
    "\n",
    "Azure: {azure}\n",
    "\n",
    "Desired Format:\n",
    "{format_instruction}\n",
    "Ensure that your calculations are accurate and well-documented. Provide references to any data sources or formulas used in the estimation process.\n",
    "\"\"\",\n",
    "    input_variables=[\"aws\", \"gcp\", \"azure\"],\n",
    "    partial_variables={\"format_instruction\": output_parser.get_format_instructions()}\n",
    "    )\n",
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722680964.808248   53325 subchannel.cc:806] subchannel 0x7ff40b3b6d50 {address=ipv6:%5B2404:6800:400a:804::200a%5D:443, args={grpc.client_channel_factory=0x7ff411313160, grpc.default_authority=generativelanguage.googleapis.com:443, grpc.dns_enable_srv_queries=1, grpc.http2_scheme=https, grpc.internal.channel_credentials=0x7ff40b61c4c0, grpc.internal.client_channel_call_destination=0x116b9a218, grpc.internal.event_engine=0x7ff40b3a7a00, grpc.internal.security_connector=0x7ff40b3a1c90, grpc.internal.subchannel_pool=0x7ff411319170, grpc.max_receive_message_length=-1, grpc.max_send_message_length=-1, grpc.primary_user_agent=grpc-python/1.65.1, grpc.resource_quota=0x7ff411314900, grpc.server_uri=dns:///generativelanguage.googleapis.com:443}}: connect failed (UNKNOWN:connect: No route to host (65) {created_time:\"2024-08-03T19:29:24.808069+09:00\"}), backing off for 999 ms\n",
      "I0000 00:00:1722680965.061562   53326 subchannel.cc:806] subchannel 0x7ff40b3b7590 {address=ipv6:%5B2404:6800:400a:80c::200a%5D:443, args={grpc.client_channel_factory=0x7ff411313160, grpc.default_authority=generativelanguage.googleapis.com:443, grpc.dns_enable_srv_queries=1, grpc.http2_scheme=https, grpc.internal.channel_credentials=0x7ff40b61c4c0, grpc.internal.client_channel_call_destination=0x116b9a218, grpc.internal.event_engine=0x7ff40b3a46d0, grpc.internal.security_connector=0x7ff40b361f40, grpc.internal.subchannel_pool=0x7ff411319170, grpc.max_receive_message_length=-1, grpc.max_send_message_length=-1, grpc.primary_user_agent=grpc-python/1.65.1, grpc.resource_quota=0x7ff411314900, grpc.server_uri=dns:///generativelanguage.googleapis.com:443}}: connect failed (UNKNOWN:connect: No route to host (65) {created_time:\"2024-08-03T19:29:25.06145+09:00\"}), backing off for 1000 ms\n",
      "I0000 00:00:1722680965.316759   53328 subchannel.cc:806] subchannel 0x7ff40b3b9390 {address=ipv6:%5B2404:6800:400a:80a::200a%5D:443, args={grpc.client_channel_factory=0x7ff411313160, grpc.default_authority=generativelanguage.googleapis.com:443, grpc.dns_enable_srv_queries=1, grpc.http2_scheme=https, grpc.internal.channel_credentials=0x7ff40b61c4c0, grpc.internal.client_channel_call_destination=0x116b9a218, grpc.internal.event_engine=0x7ff40b3839d0, grpc.internal.security_connector=0x7ff40b3b8dd0, grpc.internal.subchannel_pool=0x7ff411319170, grpc.max_receive_message_length=-1, grpc.max_send_message_length=-1, grpc.primary_user_agent=grpc-python/1.65.1, grpc.resource_quota=0x7ff411314900, grpc.server_uri=dns:///generativelanguage.googleapis.com:443}}: connect failed (UNKNOWN:connect: No route to host (65) {created_time:\"2024-08-03T19:29:25.316677+09:00\"}), backing off for 1000 ms\n",
      "I0000 00:00:1722680965.568421   53330 subchannel.cc:806] subchannel 0x7ff40b3bb1c0 {address=ipv6:%5B2404:6800:400a:805::200a%5D:443, args={grpc.client_channel_factory=0x7ff411313160, grpc.default_authority=generativelanguage.googleapis.com:443, grpc.dns_enable_srv_queries=1, grpc.http2_scheme=https, grpc.internal.channel_credentials=0x7ff40b61c4c0, grpc.internal.client_channel_call_destination=0x116b9a218, grpc.internal.event_engine=0x7ff40b3b8180, grpc.internal.security_connector=0x7ff40b3bac00, grpc.internal.subchannel_pool=0x7ff411319170, grpc.max_receive_message_length=-1, grpc.max_send_message_length=-1, grpc.primary_user_agent=grpc-python/1.65.1, grpc.resource_quota=0x7ff411314900, grpc.server_uri=dns:///generativelanguage.googleapis.com:443}}: connect failed (UNKNOWN:connect: No route to host (65) {created_time:\"2024-08-03T19:29:25.568277+09:00\"}), backing off for 999 ms\n",
      "I0000 00:00:1722680965.811682   53331 subchannel.cc:761] subchannel 0x7ff40b3b6d50 {address=ipv6:%5B2404:6800:400a:804::200a%5D:443, args={grpc.client_channel_factory=0x7ff411313160, grpc.default_authority=generativelanguage.googleapis.com:443, grpc.dns_enable_srv_queries=1, grpc.http2_scheme=https, grpc.internal.channel_credentials=0x7ff40b61c4c0, grpc.internal.client_channel_call_destination=0x116b9a218, grpc.internal.event_engine=0x7ff40b3a7a00, grpc.internal.security_connector=0x7ff40b3a1c90, grpc.internal.subchannel_pool=0x7ff411319170, grpc.max_receive_message_length=-1, grpc.max_send_message_length=-1, grpc.primary_user_agent=grpc-python/1.65.1, grpc.resource_quota=0x7ff411314900, grpc.server_uri=dns:///generativelanguage.googleapis.com:443}}: backoff delay elapsed, reporting IDLE\n",
      "I0000 00:00:1722680966.065598   53327 subchannel.cc:761] subchannel 0x7ff40b3b7590 {address=ipv6:%5B2404:6800:400a:80c::200a%5D:443, args={grpc.client_channel_factory=0x7ff411313160, grpc.default_authority=generativelanguage.googleapis.com:443, grpc.dns_enable_srv_queries=1, grpc.http2_scheme=https, grpc.internal.channel_credentials=0x7ff40b61c4c0, grpc.internal.client_channel_call_destination=0x116b9a218, grpc.internal.event_engine=0x7ff40b3a46d0, grpc.internal.security_connector=0x7ff40b361f40, grpc.internal.subchannel_pool=0x7ff411319170, grpc.max_receive_message_length=-1, grpc.max_send_message_length=-1, grpc.primary_user_agent=grpc-python/1.65.1, grpc.resource_quota=0x7ff411314900, grpc.server_uri=dns:///generativelanguage.googleapis.com:443}}: backoff delay elapsed, reporting IDLE\n",
      "I0000 00:00:1722680966.320258   53335 subchannel.cc:761] subchannel 0x7ff40b3b9390 {address=ipv6:%5B2404:6800:400a:80a::200a%5D:443, args={grpc.client_channel_factory=0x7ff411313160, grpc.default_authority=generativelanguage.googleapis.com:443, grpc.dns_enable_srv_queries=1, grpc.http2_scheme=https, grpc.internal.channel_credentials=0x7ff40b61c4c0, grpc.internal.client_channel_call_destination=0x116b9a218, grpc.internal.event_engine=0x7ff40b3839d0, grpc.internal.security_connector=0x7ff40b3b8dd0, grpc.internal.subchannel_pool=0x7ff411319170, grpc.max_receive_message_length=-1, grpc.max_send_message_length=-1, grpc.primary_user_agent=grpc-python/1.65.1, grpc.resource_quota=0x7ff411314900, grpc.server_uri=dns:///generativelanguage.googleapis.com:443}}: backoff delay elapsed, reporting IDLE\n",
      "I0000 00:00:1722680966.572312   53334 subchannel.cc:761] subchannel 0x7ff40b3bb1c0 {address=ipv6:%5B2404:6800:400a:805::200a%5D:443, args={grpc.client_channel_factory=0x7ff411313160, grpc.default_authority=generativelanguage.googleapis.com:443, grpc.dns_enable_srv_queries=1, grpc.http2_scheme=https, grpc.internal.channel_credentials=0x7ff40b61c4c0, grpc.internal.client_channel_call_destination=0x116b9a218, grpc.internal.event_engine=0x7ff40b3b8180, grpc.internal.security_connector=0x7ff40b3bac00, grpc.internal.subchannel_pool=0x7ff411319170, grpc.max_receive_message_length=-1, grpc.max_send_message_length=-1, grpc.primary_user_agent=grpc-python/1.65.1, grpc.resource_quota=0x7ff411314900, grpc.server_uri=dns:///generativelanguage.googleapis.com:443}}: backoff delay elapsed, reporting IDLE\n"
     ]
    }
   ],
   "source": [
    "calculate_result = chain.invoke({\n",
    "    \"aws\": str(repo_result.aws), \n",
    "    \"gcp\": str(repo_result.gcp), \n",
    "    \"azure\": str(repo_result.azure),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcp=Estimate(power_consumption='0.05 kWh', carbon_footprint='0.01 kg CO2', description=\"Based on the GCP Carbon Footprint calculator and considering the e2-medium instance located in us-central1 region has a sustained CPU utilization of 40%, the estimated hourly power consumption is 0.05 kWh. This calculation considers the PUE of Google Cloud's data centers. The carbon footprint is estimated to be 0.01 kg CO2 per hour, based on the region's grid carbon intensity and Google's commitment to renewable energy.\") aws=Estimate(power_consumption='0.06 kWh', carbon_footprint='0.025 kg CO2', description=\"Based on the AWS power consumption data for t3.medium instance and considering a sustained CPU utilization of 40%, the estimated hourly power consumption is 0.06 kWh. This calculation considers the PUE of AWS data centers. The carbon footprint is estimated to be 0.025 kg CO2 per hour, based on the region's grid carbon intensity and AWS's sustainability initiatives.\") azure=Estimate(power_consumption='0.07 kWh', carbon_footprint='0.03 kg CO2', description=\"Based on the Azure Sustainability Calculator and considering the Standard_B2s instance located in the eastus region has a sustained CPU utilization of 40%, the estimated hourly power consumption is 0.07 kWh. This calculation considers the PUE of Azure's data centers. The carbon footprint is estimated to be 0.03 kg CO2 per hour, based on the region's grid carbon intensity and Microsoft's commitment to renewable energy.\")\n"
     ]
    }
   ],
   "source": [
    "print(calculate_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the best instance\n",
    "- instance, language_ratio, estimation 정보를 다 모아서 마지막으로 가장 좋은 instance 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "class InstanceResult(BaseModel):\n",
    "    instance: Instance = Field(description=\"Instance information\")\n",
    "    estimate: Estimate = Field(description=\"Estimate result of instance\")\n",
    "\n",
    "class BestInstance(BaseModel):\n",
    "    conclusion: InstanceResult = Field(description=\"The most appropriate among gcp, aws, and azure\")\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=BestInstance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "# Output\n",
    "# Ensure the output is structured in a clear and detailed manner, adhering to the JSON format specified by the following guide: {format_instruction}\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"As an expert in cloud computing economics and environmental sustainability, identify the most economical and environmentally friendly instance among the provided options from AWS, GCP, and Azure.\n",
    "\n",
    "Instructions:\n",
    "Analyze the instance specifications and estimation results provided for each cloud provider.\n",
    "Compare the hourly cost and carbon footprint of each instance.\n",
    "Determine which instance offers the best balance of cost efficiency and low environmental impact.\n",
    "Clearly explain the reasoning behind your choice, supported by data.\n",
    "\n",
    "Instance Specifications and Estimation Results:\n",
    "\n",
    "AWS: {aws}\n",
    "\n",
    "GCP: {gcp}\n",
    "\n",
    "Azure: {azure}\n",
    "\n",
    "Desired Format:\n",
    "{format_instruction}\n",
    "\n",
    "Ensure that your analysis is thorough and well-documented. Provide references to any data sources or formulas used in the estimation process.\n",
    "\"\"\",\n",
    "    input_variables=[\"aws\", \"gcp\", \"azure\"],\n",
    "    partial_variables={\"format_instruction\": output_parser.get_format_instructions()}\n",
    "    )\n",
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws = InstanceResult(instance=repo_result.aws, estimate=calculate_result.aws)\n",
    "gcp = InstanceResult(instance=repo_result.gcp, estimate=calculate_result.gcp)\n",
    "azure = InstanceResult(instance=repo_result.azure, estimate=calculate_result.azure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_instance_result = chain.invoke({\n",
    "    \"aws\": str(aws), \n",
    "    \"gcp\": str(gcp), \n",
    "    \"azure\": str(azure),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_instance = gemini_best_instance_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalResponse(BaseModel):\n",
    "    aws: InstanceResult = Field(description=\"Information of instance and estimation\")\n",
    "    gcp: InstanceResult = Field(description=\"Information of instance and estimation\")\n",
    "    azure: InstanceResult = Field(description=\"Information of instance and estimation\")\n",
    "    conclusion: InstanceResult = Field(description=\"The most appropriate among gcp, aws, and azure\")\n",
    "    language_ratio: Dict[str, int] = Field(description=\"The key value is the programming language used and the value is the number of bytes the programming language is used in the entire repository.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(aws=InstanceResult(instance=Instance(cloud_provider='AWS', name='t3.medium', cpu=2, ram=4.0, storage=10, gpu=None, region='us-east-1', cost_per_hour=0.0441, description=\"This application requires a minimum of 2 vCPUs and 2GB of RAM to run. A simple Java application with Spring Boot and MySQL usually doesn't demand high CPU or memory resources. Therefore, a t3.medium instance, which provides a balance of performance and cost, is chosen. 10GB of storage is sufficient for this application and its data. The application does not require a GPU. The us-east-1 region offers a good balance of cost and latency for many users.\"), estimate=Estimate(power_consumption='0.06 kWh', carbon_footprint='0.025 kg CO2', description=\"Based on the AWS power consumption data for t3.medium instance and considering a sustained CPU utilization of 40%, the estimated hourly power consumption is 0.06 kWh. This calculation considers the PUE of AWS data centers. The carbon footprint is estimated to be 0.025 kg CO2 per hour, based on the region's grid carbon intensity and AWS's sustainability initiatives.\")), gcp=InstanceResult(instance=Instance(cloud_provider='GCP', name='e2-medium', cpu=1, ram=4.0, storage=10, gpu=None, region='us-central1', cost_per_hour=0.0169861111111111, description=\"This application requires a minimum of 2 vCPUs and 2GB of RAM to run. A simple Java application with Spring Boot and MySQL usually doesn't demand high CPU or memory resources. Therefore, an e2-medium instance, which provides a balance of performance and cost, is chosen. 10GB of storage is sufficient for this application and its data. The application does not require a GPU. The us-central1 region offers a good balance of cost and latency for many users.\"), estimate=Estimate(power_consumption='0.05 kWh', carbon_footprint='0.01 kg CO2', description=\"Based on the GCP Carbon Footprint calculator and considering the e2-medium instance located in us-central1 region has a sustained CPU utilization of 40%, the estimated hourly power consumption is 0.05 kWh. This calculation considers the PUE of Google Cloud's data centers. The carbon footprint is estimated to be 0.01 kg CO2 per hour, based on the region's grid carbon intensity and Google's commitment to renewable energy.\")), azure=InstanceResult(instance=Instance(cloud_provider='Azure', name='Standard_B2s', cpu=2, ram=4.0, storage=10, gpu='None', region='eastus', cost_per_hour=0.0456, description=\"This application requires a minimum of 2 vCPUs and 2GB of RAM to run. A simple Java application with Spring Boot and MySQL usually doesn't demand high CPU or memory resources. Therefore, a Standard_B2s instance, which provides a balance of performance and cost, is chosen. 10GB of storage is sufficient for this application and its data. The application does not require a GPU. The eastus region offers a good balance of cost and latency for many users.\"), estimate=Estimate(power_consumption='0.07 kWh', carbon_footprint='0.03 kg CO2', description=\"Based on the Azure Sustainability Calculator and considering the Standard_B2s instance located in the eastus region has a sustained CPU utilization of 40%, the estimated hourly power consumption is 0.07 kWh. This calculation considers the PUE of Azure's data centers. The carbon footprint is estimated to be 0.03 kg CO2 per hour, based on the region's grid carbon intensity and Microsoft's commitment to renewable energy.\")), conclusion=InstanceResult(instance=Instance(cloud_provider='GCP', name='e2-medium', cpu=1, ram=4.0, storage=10, gpu='None', region='us-central1', cost_per_hour=0.0169861111111111, description=\"This application requires a minimum of 2 vCPUs and 2GB of RAM to run. A simple Java application with Spring Boot and MySQL usually doesn't demand high CPU or memory resources. Therefore, an e2-medium instance, which provides a balance of performance and cost, is chosen. 10GB of storage is sufficient for this application and its data. The application does not require a GPU. The us-central1 region offers a good balance of cost and latency for many users.\"), estimate=Estimate(power_consumption='0.05 kWh', carbon_footprint='0.01 kg CO2', description=\"Based on the GCP Carbon Footprint calculator and considering the e2-medium instance located in us-central1 region has a sustained CPU utilization of 40%, the estimated hourly power consumption is 0.05 kWh. This calculation considers the PUE of Google Cloud's data centers. The carbon footprint is estimated to be 0.01 kg CO2 per hour, based on the region's grid carbon intensity and Google's commitment to renewable energy.\")), language_ratio={'Kotlin': 1754, 'Properties': 1056, 'YAML': 810, 'Shell': 3607, 'Batch': 2830, 'JSON': 2742})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_response = FinalResponse(\n",
    "    aws=aws, \n",
    "    gcp=gcp, \n",
    "    azure=azure, \n",
    "    conclusion=best_instance.conclusion, \n",
    "    language_ratio=repo_result.language_ratio\n",
    ")\n",
    "final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
