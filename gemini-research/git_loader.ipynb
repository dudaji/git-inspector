{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import GitLoader\n",
    "\n",
    "repo_path = \"./repo/todo\"\n",
    "loader = GitLoader(\n",
    "    # clone_url=\"https://github.com/dudaji/git-inspector.git\",\n",
    "    clone_url=\"https://github.com/rjwharry/todo.git\",\n",
    "    repo_path=repo_path,\n",
    "    branch=\"main\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loader.load()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = list(filter(lambda d: d.metadata[\"source\"].startswith(\"backend/\"), data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(backend))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'backend/kotlin/src/main/kotlin/com/practice/kotlin/services/TodoService.kt', 'file_path': 'backend/kotlin/src/main/kotlin/com/practice/kotlin/services/TodoService.kt', 'file_name': 'TodoService.kt', 'file_type': '.kt'}, page_content='package com.practice.kotlin.services\\n\\nimport com.practice.kotlin.dto.TodoDto\\nimport com.practice.kotlin.repositories.STATUS\\nimport com.practice.kotlin.repositories.Todo\\nimport com.practice.kotlin.repositories.TodoRepository\\nimport org.springframework.stereotype.Service\\n\\n@Service\\nclass TodoService(private val todoRepository: TodoRepository) {\\n\\tfun getAllTodos(): List<Todo> {\\n\\t\\treturn todoRepository.findAll()\\n\\t}\\n\\n\\tfun getTodoById(id: Long): Todo {\\n\\t\\treturn todoRepository.findById(id).get()\\n\\t}\\n\\n\\n\\tfun createTodo(todo: Todo): Todo {\\n\\t\\tval lastTodo = getLastTodoByStatus(todo.status)\\n\\t\\tval newTodo = todoRepository.save(todo)\\n\\t\\tnewTodo.prev = lastTodo?.id\\n\\t\\tnewTodo.next = null\\n\\t\\ttodoRepository.save(newTodo)\\n\\t\\tlastTodo?.let {\\n\\t\\t\\tlastTodo.next = newTodo.id\\n\\t\\t\\ttodoRepository.save(lastTodo)\\n\\t\\t}\\n\\t\\treturn newTodo\\n\\t}\\n\\n\\tfun updateTodo(id: Long, body: TodoDto): Todo {\\n\\t\\tval todo = deleteFromLinkedList(id)\\n\\t\\tval updatedTodo = insertToLinkedList(todo, body.prev, body.next)\\n\\t\\tupdatedTodo.name = body.todo.name\\n\\t\\tupdatedTodo.contents = body.todo.contents\\n\\t\\tupdatedTodo.status = body.todo.status\\n\\t\\treturn todoRepository.save(updatedTodo)\\n\\t}\\n\\n\\tfun insertToLinkedList(todo: Todo, prev: Long?, next: Long?): Todo {\\n\\t\\tif (prev == -1L || next == -1L) return todo\\n\\t\\tval prevTodo = if (prev != null) getTodoById(prev) else null\\n\\t\\tval nextTodo = if (next != null) getTodoById(next) else null\\n\\t\\ttodo.prev = prev\\n\\t\\ttodo.next = next\\n\\t\\tprevTodo?.let {\\n\\t\\t\\tit.next = todo.id\\n\\t\\t\\ttodoRepository.save(it)\\n\\t\\t}\\n\\t\\tnextTodo?.let {\\n\\t\\t\\tit.prev = todo.id\\n\\t\\t\\ttodoRepository.save(it)\\n\\t\\t}\\n\\t\\treturn todo\\n\\t}\\n\\n\\tfun deleteTodo(id: Long): Todo {\\n\\t\\tval todo = deleteFromLinkedList(id)\\n\\t\\ttodoRepository.deleteById(id)\\n\\t\\treturn todo\\n\\t}\\n\\n\\tfun deleteFromLinkedList(id: Long): Todo {\\n\\t\\tval todo = getTodoById(id)\\n\\t\\tval prevTodo = if (todo.prev != null) getTodoById(todo.prev!!) else null\\n\\t\\tval nextTodo = if (todo.next != null) getTodoById(todo.next!!) else null\\n\\t\\tprevTodo?.let {\\n\\t\\t\\tit.next = nextTodo?.id\\n\\t\\t\\ttodoRepository.save(it)\\n\\t\\t}\\n\\t\\tnextTodo?.let {\\n\\t\\t\\tit.prev = prevTodo?.id\\n\\t\\t\\ttodoRepository.save(it)\\n\\t\\t}\\n\\t\\treturn todo\\n\\t}\\n\\n\\tfun getLastTodoByStatus(status: STATUS): Todo? {\\n\\t\\treturn todoRepository.findByStatusAndNextIsNull(status)\\n\\t}\\n}')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backend[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Git Analyzer\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dudaji/anaconda3/envs/llm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722603488.689705  360924 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n",
      "I0000 00:00:1722603488.700513  360924 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1722603488.702067  360924 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"models/gemini-1.5-pro-latest\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Cost(BaseModel):\n",
    "    # monthly: str = Field(description=\"Estimated monthly measurements\")\n",
    "    hourly: str = Field(description=\"Estimated measurements per hour\")\n",
    "\n",
    "class Instance(BaseModel):\n",
    "    cloud_provider: str = Field(description=\"Name of cloud provider (GCP or AWS or Azure)\")\n",
    "    name: str = Field(description=\"Name of instance type\")\n",
    "    cpu: int = Field(description=\"The number of instance cpu cores\")\n",
    "    ram: float = Field(description=\"The capacity of instance ram (GiB)\")\n",
    "    storage: int = Field(description=\"The capacity of instance storage (GiB)\")\n",
    "    gpu: str = Field(description=\"Name of gpu model and memory (GiB) of instance\")\n",
    "    region: str = Field(description=\"Region of instance\")\n",
    "    cost: Cost = Field(description=\"Monthly and Hourly cost of instance\")\n",
    "\n",
    "class Estimate(BaseModel):\n",
    "    instance: Instance = Field(description=\"Instance information of Cloud Provider\")\n",
    "    # pricing: Cost = Field(description=\"Estimated pricing while running an instance of the instance_type (USD)\")\n",
    "    power_consumption: Cost = Field(description=\"Estimated power consumption while running an instance of the instance_type(kWh)\")\n",
    "    carbon_footprint: Cost = Field(description=\"Estimated carbon footprint while running an instance of the instance_type(kg CO2)\")\n",
    "    description: str = Field(description=\"A rationale and detailed explanation for estimations\")\n",
    "    \n",
    "\n",
    "class Result(BaseModel):\n",
    "    gcp: Estimate = Field(description=\"Estimated Result of Google Cloud Platform(GCP)\")\n",
    "    aws: Estimate = Field(description=\"Estimated Result of Amazon Web Services(AWS)\")\n",
    "    azure: Estimate = Field(description=\"Estimated Result of Microsoft Azure\")\n",
    "    # conclusion: Estimate = Field(description=\"The most appropriate among gcp, aws, and azure\")\n",
    "    language_ratio: Dict[str, int] = Field(description=\"The key value is the programming language used and the value is the number of bytes in which the programming language is used.\")\n",
    "\n",
    "output_parser = JsonOutputParser(pydantic_object=Result)\n",
    "# output_parser = JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# Output\n",
    "# Ensure the output is structured in a clear and detailed manner, adhering to the JSON format specified by the following guide: {format_instruction}\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "As an expert in analyzing software repositories and estimating resource consumption and environmental impact, your task is to provide a comprehensive analysis of a GitHub repository.\n",
    "\n",
    "Instructions\n",
    "Analyze the structure of the files in the provided GitHub repository by examining the metadata in the documentation.\n",
    "Identify the entry point of the repository.\n",
    "Determine the minimum resources required to run the repository on GCP, AWS, and Azure platforms.\n",
    "Estimate the power consumption, and carbon footprint on each platform.\n",
    "{format_instruction}\n",
    "Context\n",
    "The goal is to gain a detailed understanding of the repositoryâ€™s requirements and its environmental impact. Your analysis should be thorough, taking into account all relevant aspects of the repository and the different cloud platforms.\n",
    "\n",
    "\n",
    "GitHub Repository\n",
    "{GITHUB}\n",
    "\n",
    "Additional Guidelines\n",
    "Be specific and detailed in your analysis.\n",
    "Provide calculations and assumptions used in estimating resources and environmental impact.\n",
    "Compare and contrast the findings across the three cloud platforms (GCP, AWS, Azure).\n",
    "Use technical terminology appropriately to convey precision and expertise.\n",
    "\"\"\",\n",
    "    input_variables=[\"GITHUB\"],\n",
    "    partial_variables={\"format_instruction\": output_parser.get_format_instructions()}\n",
    "    )\n",
    "chain = prompt | llm | output_parser\n",
    "# chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722603507.831725  363223 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722603507.832005  363223 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gcp': {'instance': {'cloud_provider': 'GCP',\n",
       "   'name': 'e2-micro',\n",
       "   'cpu': '2',\n",
       "   'ram': 0.6,\n",
       "   'storage': 30,\n",
       "   'gpu': 'None',\n",
       "   'region': 'us-central1',\n",
       "   'cost': {'monthly': '$13.04', 'hourly': '$0.006'}},\n",
       "  'power_consumption': {'monthly': '9.78 kWh', 'hourly': '0.004 kWh'},\n",
       "  'carbon_footprint': {'monthly': '4.401 kg CO2', 'hourly': '0.002 kg CO2'},\n",
       "  'description': \"This Kotlin Spring Boot application, connecting to a MySQL database, can be run on a minimal GCP e2-micro instance. The e2-micro, with 2 vCPUs and 0.6 GB memory, suffices for development and light traffic. We estimate 30GB storage for the application and database. The estimated cost is based on GCP's pricing, and power consumption is a conservative estimate. The carbon footprint is derived using US-central1's carbon efficiency.  \"},\n",
       " 'aws': {'instance': {'cloud_provider': 'AWS',\n",
       "   'name': 't4g.nano',\n",
       "   'cpu': '2',\n",
       "   'ram': 0.5,\n",
       "   'storage': 20,\n",
       "   'gpu': 'None',\n",
       "   'region': 'us-east-1',\n",
       "   'cost': {'monthly': '$10.24', 'hourly': '$0.004'}},\n",
       "  'power_consumption': {'monthly': '7.68 kWh', 'hourly': '0.003 kWh'},\n",
       "  'carbon_footprint': {'monthly': '3.456 kg CO2', 'hourly': '0.001 kg CO2'},\n",
       "  'description': \"For AWS, a t4g.nano instance (2 vCPU, 0.5 GB memory) is suitable. 20GB storage is allocated for application and database files. Cost calculation is based on AWS pricing, and power consumption is a conservative estimate for this instance type. The carbon footprint is calculated using us-east-1's carbon efficiency data.  \"},\n",
       " 'azure': {'instance': {'cloud_provider': 'Azure',\n",
       "   'name': 'B1s',\n",
       "   'cpu': '1',\n",
       "   'ram': 1,\n",
       "   'storage': 30,\n",
       "   'gpu': 'None',\n",
       "   'region': 'eastus',\n",
       "   'cost': {'monthly': '$13.34', 'hourly': '$0.005'}},\n",
       "  'power_consumption': {'monthly': '9.99 kWh', 'hourly': '0.004 kWh'},\n",
       "  'carbon_footprint': {'monthly': '4.496 kg CO2', 'hourly': '0.002 kg CO2'},\n",
       "  'description': \"Azure's B1s instance (1 vCPU, 1 GB memory) is a good fit. 30GB storage is allocated for the application and database. Cost estimation is based on Azure's pricing, and power consumption is a conservative estimate. The carbon footprint is derived using Azure's carbon emission data for the eastus region. \"},\n",
       " 'language_ratio': {'Kotlin': 12215,\n",
       "  'Properties': 1246,\n",
       "  'YAML': 804,\n",
       "  'JSON': 1782}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for chunk in chain.stream({\"GITHUB\": backend}):\n",
    "#     print(chunk, end=\"\", flush=True)\n",
    "answer = chain.invoke({\"GITHUB\": backend})\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
